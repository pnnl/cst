

https://inqira.io/q/which-database-is-better-for-handling-time-series-data-postgresql-or-mysql

PostgreSQL has some unique features that make it particularly well-suited for time-series data. For example, it has a specialized data type called timestamp with time zone that makes it easy to work with data across different time zones. It also has support for range types and window functions that are useful for analyzing time-series data. Additionally, PostgreSQL has excellent support for indexing, which can greatly improve query performance.





source .env

# Install yq (https://github.com/mikefarah/yq/#install) to parse the YAML file and retrieve the network name
NETWORK_NAME=$(yq eval '.networks' postgres-docker-compose.yaml | cut -f 1 -d':')
docker network create $NETWORK_NAME
# or hardcode the network name from the YAML file
# docker network create etl_network

docker-compose --env-file ./.env -f ./postgres-docker-compose.yaml up -d




// Persist in postgress data files
https://stackoverflow.com/questions/41637505/how-to-persist-data-in-a-dockerized-postgres-database-using-volumes


You can create a common volume for all Postgres data >>
docker volume create pgdata

or you can set it to the compose file >>

version: "3"
services:
  db:
    image: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgress
      - POSTGRES_DB=postgres
    ports:
      - "5433:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - suruse
volumes:
  pgdata:
It will create volume name pgdata and mount this volume to container's path.


You can inspect this volume >>
docker volume inspect pgdata